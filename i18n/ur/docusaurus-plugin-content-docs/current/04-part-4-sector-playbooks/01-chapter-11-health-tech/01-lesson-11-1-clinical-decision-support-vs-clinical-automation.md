---
id: 01-lesson-11-1-clinical-decision-support-vs-clinical-automation
title: "کلینیکل ڈیسیژن سپورٹ (CDS) بمقابلہ کلینیکل آٹومیشن"
sidebar_label: "کلینیکل ڈیسیژن سپورٹ بمقابلہ آٹومیشن"
---

# کلینیکل ڈیسیژن سپورٹ (CDS) بمقابلہ کلینیکل آٹومیشن

صحت کی دیکھ بھال کے حساس ماحول میں، ڈاکٹر کی "مدد" کرنے اور ڈاکٹر کی جگہ "خودکار نظام" لانے کے درمیان فرق محض لفظی نہیں ہے؛ بلکہ یہ محفوظ جدت اور خطرناک لاپرواہی کے درمیان کی لکیر ہے۔ یہ سبق طب میں اے آئی کے آپریشنل نمونوں کی وضاحت کرتا ہے، جس میں "انسان کی حکمرانی" (Human-in-Command) کے اصول پر زور دیا گیا ہے۔

## خود مختاری کا تسلسل

ہم طبی اے آئی سسٹمز کو خود مختاری کے درجوں میں تقسیم کرتے ہیں، جیسے کہ خود ڈرائیو ہونے والی کاریں:

*   **لیول 0 (کوئی اے آئی نہیں):** روایتی دستی تشخیص۔
*   **لیول 1 (معاونت):** اے آئی ایکس رے پر کسی مشتبہ حصے کی نشاندہی کرتا ہے۔ ڈاکٹر کو ابھی بھی اسے دیکھنا، تشریح کرنا اور فیصلہ کرنا ہوتا ہے۔
*   **لیول 2 (جزوی آٹومیشن):** اے آئی ریڈیولوجی رپورٹ کا مسودہ تیار کرتا ہے۔ ڈاکٹر اس کا جائزہ لیتا ہے، ترمیم کرتا ہے اور دستخط کرتا ہے۔ ڈاکٹر قانونی طور پر اس کا مصنف ہوتا ہے۔
*   **لیول 3 (مشروط آٹومیشن):** اے آئی خود بخود "نارمل" کیسز کو فہرست میں نیچے اور "خطرناک" کیسز کو سب سے اوپر کر دیتا ہے۔ یہ کام کے بہاؤ پر اثر انداز ہوتا ہے لیکن حتمی تشخیص پر نہیں۔
*   **لیول 4 (اعلیٰ آٹومیشن):** اے آئی سادہ حالات (مثلاً انسولین کی خودکار خوراک) کے لیے تشخیص اور علاج تجویز کرتا ہے، لیکن انسانی نگرانی میں۔

**موجودہ صورتحال:** زیادہ تر محفوظ سسٹمز لیول 1 یا 2 پر کام کرتے ہیں۔ مقصد "بڑھائی گئی ذہانت" (Augmented Intelligence) ہے، جہاں `ڈاکٹر + اے آئی > ڈاکٹر` اور `ڈاکٹر + اے آئی > اے آئی` ہوتا ہے۔

## کلینیکل ڈیسیژن سپورٹ (CDS)

CDS سسٹمز ڈاکٹر کی سوچنے سمجھنے کی صلاحیتوں کو بڑھانے کے لیے بنائے گئے ہیں، نہ کہ ان کی جگہ لینے کے لیے۔

*   **"دوسرا قاری" (Second Reader) کا طریقہ کار:** ریڈیولوجی میں، اے آئی ایک دوسری آنکھ کے طور پر کام کرتا ہے۔ ریڈیولوجسٹ کے معائنے کے بعد، اے آئی کسی چھوٹی رسولی (nodule) کی نشاندہی کر سکتا ہے جو شاید نظر سے رہ گئی ہو۔ یہ تلاش کے دوران ہونے والی انسانی خطاؤں کو کم کرتا ہے۔
*   **الرٹ کی تھکن:** CDS میں ایک بڑا خطرہ ضرورت سے زیادہ الرٹس ہیں۔ اگر اے آئی ہر چھوٹی دوائی کے تعامل پر الارم بجانا شروع کر دے، تو ڈاکٹر تمام الرٹس کو نظر انداز کر دیتے ہیں۔ لہذا، صرف سنگین حالات (مثلاً مریض کو جان لیوا الرجی والی دوا تجویز کرنا) پر ہی ڈاکٹر کو متوجہ کرنا چاہیے۔

## "سائے والا آٹومیشن" (Shadow Automation) کے خطرات

یہ تب ہوتا ہے جب سسٹم نظریاتی طور پر لیول 2 (انسانی جائزہ ضروری) ہو لیکن عملی طور پر لیول 4 (انسان صرف مہر لگا رہا ہو) بن جائے۔

*   **آٹومیشن کا تعصب (Automation Bias):** تحقیق سے پتہ چلتا ہے کہ اگر اے آئی پراعتماد طریقے سے تشخیص پیش کرے، تو جونیئر ڈاکٹر اکثر اسے قبول کر لیتے ہیں چاہے وہ طبی شواہد کے خلاف ہی کیوں نہ ہو۔ یہ عملی طور پر انسانی حفاظتی تہہ کو ختم کر دیتا ہے۔
*   **تدارک:** سسٹمز کو "سوچنے پر مجبور کرنے والے افعال" استعمال کرنے چاہئیں۔ مثال کے طور پر، اے آئی کو اپنی تشخیص تب تک ظاہر نہیں کرنی چاہیے جب تک ڈاکٹر اپنی ابتدائی رائے درج نہ کر دے۔ یہ انسان کو مشین کا جواب دیکھنے سے پہلے آزادانہ طور پر سوچنے پر مجبور کرتا ہے۔

## ریگولیٹری ماحول (SaMD)

میڈیکل ڈیوائس کے طور پر سافٹ ویئر (SaMD) کے قوانین (جیسے FDA) ان سسٹمز کی سختی سے درجہ بندی کرتے ہیں۔
*   **خطرہ کی درجہ بندی:** قدم گننے والی ایک عام ایپ "کم خطرہ" ہے۔ کینسر کی تشخیص کرنے والی اے آئی "اعلیٰ خطرہ" (کلاس III) ہے۔
*   **طبی توثیق:** زیادہ خطرے والے سسٹمز کے لیے بڑے پیمانے پر طبی آزمائش (clinical trials) ضروری ہوتی ہیں تاکہ یہ ثابت ہو سکے کہ کیا اس سے مریض کی بقا کی شرح میں اضافہ ہوا ہے یا نہیں۔

صحت کے شعبے میں، الگورتھم بنانا آسان کام ہے۔ مشکل کام اس الگورتھم کو ڈاکٹروں کے کام کے پیچیدہ طریقے میں اس طرح شامل کرنا ہے کہ "کسی کو نقصان نہ پہنچے" (Do No Harm) کے عہد کی پاسداری ہو۔