---
id: 01-lesson-33-1-glossary-of-technical-and-policy-terms
title: "اے آئی اور ایجنٹک اصطلاحات کی مکمل فرہنگ (A-Z)"
sidebar_label: "A-Z فرہنگ"
---

# اے آئی اور ایجنٹک اصطلاحات کی مکمل فرہنگ (A-Z)

مصنوعی ذہانت (AI)، خود مختار ایجنٹس، روبوٹکس، اور اخلاقیات سے متعلق اصطلاحات کا ایک جامع حوالہ۔

## A

*   **Action Space (عمل کی وسعت):** ان تمام ممکنہ اعمال کا مجموعہ جو ایک ایجنٹ کسی خاص ماحول میں انجام دے سکتا ہے۔
*   **Activation Function (فعال کرنے کا فنکشن):** ایک ریاضیاتی فنکشن (جیسے ReLU یا Sigmoid) جو نیورل نیٹ ورک کے نوڈ کے آؤٹ پٹ پر لاگو کیا جاتا ہے تاکہ اس میں غیر خطی (non-linearity) خصوصیت پیدا کی جا سکے۔
*   **Active Learning (فعال سیکھنا):** تربیت کا ایک ایسا عمل جہاں ماڈل ان ڈیٹا پوائنٹس کی نشاندہی کرتا ہے جہاں وہ الجھن کا شکار ہو، اور پھر انسان سے خاص طور پر ان پوائنٹس کو لیبل کرنے کی درخواست کرتا ہے۔
*   **Actor-Critic:** ری انفورسمنٹ لرننگ (RL) کا ایک آرکیٹیکچر جو دو نیٹ ورکس پر مشتمل ہوتا ہے: ایک ایکٹر (جو فیصلہ کرتا ہے کہ کون سا عمل کرنا ہے) اور دوسرا کریٹک (جو اس عمل کی قدر کا اندازہ لگاتا ہے)۔
*   **Adversarial Example (حریفانہ مثال):** ایک ایسی ان پٹ جسے ماڈل کو غلطی پر مجبور کرنے کے لیے ڈیزائن کیا گیا ہو (مثلاً پانڈا کی تصویر میں ایسی آواز شامل کرنا جسے انسان نہ دیکھ سکے لیکن اے آئی اسے بندر قرار دے دے)۔
*   **Adversarial Robustness (حریفانہ استحکام):** حریفانہ حملوں کے خلاف ماڈل کی مزاحمت کی پیمائش۔
*   **Agency (اختیار):** کسی اے آئی سسٹم کی وہ صلاحیت جس کے تحت وہ کسی ہدف کو حاصل کرنے کے لیے آزادانہ طور پر کام کر سکے۔
*   **Agentic Workflow (ایجنٹک ورک فلو):** ایک ایسا سسٹم ڈیزائن جہاں ایل ایل ایم (LLMs) صرف متن تیار کرنے کے بجائے چیزوں کو دہرانے، منصوبہ بندی کرنے اور ٹولز استعمال کرنے کے قابل ہوں۔
*   **AGI (مجموعی مصنوعی ذہانت):** ایک مفروضی اے آئی جو انسانی سطح پر مختلف کاموں کو سمجھنے، سیکھنے اور ان پر عمل کرنے کی صلاحیت رکھتی ہو۔
*   **Alignment (ہم آہنگی):** تحقیق کا وہ شعبہ جو اس بات کو یقینی بناتا ہے کہ اے آئی سسٹمز ایسے اہداف کا پیچھا کریں جو انسانی اقدار کے مطابق ہوں۔
*   **Alignment Tax (ہم آہنگی کا ٹیکس):** کسی ہم آہنگ ماڈل کی کارکردگی میں وہ کمی جو غیر ہم آہنگ ماڈل کے مقابلے میں آسکتی ہے (مثلاً ایک ایسا ماڈل جو غیر محفوظ جوابات دینے سے انکار کرے، وہ شاید کم مددگار لگے)۔
*   **Amortized Inference:** سیکھنے کے عمل کے اخراجات کو کئی مراحل پر تقسیم کرنا۔
*   **Anchor (لنگر):** تشریح کے عمل میں ایک ایسا اصول جو پیشگوئی کو بنیاد فراہم کرے۔
*   **ANN (مصنوعی نیورل نیٹ ورک):** کمپیوٹنگ کے وہ سسٹمز جو انسانی دماغ کے حیاتیاتی نیورل نیٹ ورکس سے متاثر ہوکر بنائے گئے ہوں۔
*   **Attention Mechanism (توجہ کا نظام):** نیورل نیٹ ورکس میں ایک ایسی تکنیک جو ماڈل کو آؤٹ پٹ تیار کرتے وقت ان پٹ کے مخصوص حصوں پر توجہ مرکوز کرنے کی اجازت دیتی ہے۔
*   **Auto-GPT:** جی پی ٹی-4 (GPT-4) کو مکمل طور پر خود مختار بنانے کی ایک تجرباتی اوپن سورس کوشش۔
*   **Autoencoder:** نیورل نیٹ ورک کی ایک قسم جو اپنی ان پٹ کو آؤٹ پٹ پر کاپی کرنے کے لیے ٹرین کی جاتی ہے، یہ ڈیٹا کی پیچیدگی کو کم کرنے کے لیے مفید ہے۔
*   **Autonomy Levels (خود مختاری کے درجات):** خود مختار سسٹمز کی درجہ بندی کا ایک پیمانہ (0-5) جو شروع میں خود کار گاڑیوں کے لیے بنایا گیا تھا لیکن اب ایجنٹس پر بھی لاگو ہوتا ہے۔
*   **Autoregressive Model:** ایک ایسا ماڈل جو پچھلی اقدار کی بنیاد پر کسی سلسلے (sequence) میں اگلی قدر کی پیشگوئی کرتا ہے (جیسے GPT)۔

## B

*   **Backpropagation:** نیورل نیٹ ورکس کو ٹرین کرنے کا الگورتھم جو نقص (loss) کو کم کرنے کے لیے وزن (weights) میں تبدیلی کا حساب لگاتا ہے۔
*   **Batch Normalization:** تربیت کے عمل کو مستحکم بنانے کی ایک تکنیک۔
*   **Bayesian Neural Network:** ایک ایسا نیورل نیٹ ورک جو اپنی پیشگوئیوں میں غیر یقینی صورتحال کا اندازہ لگانے کے لیے شماریات (Bayesian statistics) کا استعمال کرتا ہے۔
*   **Beam Search:** ایک ایسا الگورتھم جو جواب کی تیاری کے دوران صرف بہترین راستے کے بجائے کئی ممکنہ راستوں (beams) کا جائزہ لیتا ہے۔
*   **Behavioral Cloning:** ری انفورسمنٹ لرننگ کی ایک قسم جہاں ایجنٹ کسی ماہر کے کام کو دیکھ کر سیکھتا ہے۔
*   **Bias (الگورتھمی تعصب):** الگورتھم کے نتائج میں ناانصافی یا امتیازی سلوک، جو اکثر ناقص ٹریننگ ڈیٹا کی وجہ سے ہوتا ہے۔
*   **Bias (تصدیقی تعصب):** معلومات کو اس طرح تلاش کرنے یا سمجھنے کا رجحان جو انسان کے پہلے سے موجود عقائد کی تصدیق کرے۔
*   **Bias (انڈکٹیو تعصب):** وہ مفروضات جو سسٹم نئی معلومات کے بارے میں پیشگوئی کرنے کے لیے استعمال کرتا ہے۔
*   **Black Box (بلیک باکس):** ایسا سسٹم جس کے اندرونی کام کرنے کا طریقہ صارف کے لیے واضح نہ ہو (مثلاً ڈیپ نیورل نیٹ ورک)۔
*   **Blackboard Architecture:** ایک ایسا ڈیزائن جہاں کئی مختلف ایجنٹس ایک مشترکہ میموری (blackboard) کو استعمال کرتے ہوئے مل کر کسی مسئلے کو حل کرتے ہیں۔
*   **Blue-Green Deployment:** ایک ایسی حکمت عملی جس میں دو ایک جیسے سسٹمز بیک وقت چلا کر لانچ کے دوران خطرات کو کم کیا جاتا ہے۔
*   **Bounded Rationality:** یہ نظریہ کہ فیصلے کرنے کی صلاحیت دستیاب معلومات، دماغی حد اور وقت کی پابندیوں کی وجہ سے محدود ہوتی ہے۔

## C

*   **Capacity (صلاحیت):** کسی ماڈل کی پیچیدہ فنکشنز کو سمجھنے کی صلاحیت، جس کا تعلق اس کے پیرامیٹرز کی تعداد سے ہوتا ہے۔
*   **Catastrophic Forgetting (تباہ کن فراموشی):** جب ایک نیورل نیٹ ورک نئی معلومات سیکھتے وقت پرانی معلومات کو مکمل طور پر بھول جائے۔
*   **Chain of Density:** خلاصہ سازی کے عمل میں معلومات کو مزید جامع بنانے کی ایک تکنیک۔
*   **Chain of Thought (سوچ کا تسلسل):** ایک ایسی تکنیک جہاں ماڈل سے "مرحلہ وار سوچنے" کا کہا جاتا ہے تاکہ وہ مشکل سوالات کے بہتر جواب دے سکے۔
*   **Chatbot (چیٹ بوٹ):** ایک سافٹ ویئر جو تحریر یا آواز کے ذریعے آن لائن بات چیت کرتا ہے۔
*   **CLIP:** ایک ماڈل جو متن اور تصاویر کو آپس میں جوڑنے کے لیے ٹرین کیا گیا ہے۔
*   **Cold Start Problem:** نئے صارفین یا اشیاء کے لیے سفارشات (recommendations) تیار کرنے میں دشواری کیونکہ ان کے بارے میں پہلے سے کوئی ڈیٹا موجود نہیں ہوتا۔
*   **Computer Vision (کمپیوٹر ویژن):** اے آئی کا وہ شعبہ جو کمپیوٹر کو تصاویر اور بصری دنیا کو سمجھنے کی تربیت دیتا ہے۔
*   **Confidence Calibration:** اس بات کی پیمائش کہ ماڈل کی پیشگوئی کا احتمال (probability) اس کی اصل درستی سے کتنا میل کھاتا ہے۔
*   **Constitutional AI:** اینتھروپک (Anthropic) کا تیار کردہ طریقہ جہاں ماڈلز کو انسانی لیبلز کے بجائے اصولوں (آئین) کے ذریعے ٹرین کیا جاتا ہے۔
*   **Content Moderation (مواد کی نگرانی):** صارفین کے تیار کردہ مواد کی نگرانی اور اسے فلٹر کرنا۔
*   **Context Window (سیاق و سباق کی حد):** متن کی وہ مقدار جو ماڈل ایک وقت میں "دیکھ" سکتا ہے۔
*   **Contrastive Learning:** ایک تکنیک جہاں ماڈل ملتی جلتی اور مختلف چیزوں کے درمیان فرق کرنا سیکھتا ہے۔
*   **Convolutional Neural Network (CNN):** نیورل نیٹ ورک کی وہ قسم جو خاص طور پر تصاویر کے تجزیے کے لیے استعمال ہوتی ہے۔
*   **Counterfactual:** ایک سوچ کا تجربہ: "اگر ایکس (X) نہ ہوتا تو کیا ہوتا؟" یہ سسٹم کی وضاحت کے لیے استعمال ہوتا ہے۔
*   **Cooperation (باہمی تعاون):** ملٹی ایجنٹ سسٹمز میں ایجنٹس کی مل کر کام کرنے کی صلاحیت۔

## D

*   **Data Augmentation (ڈیٹا میں اضافہ):** موجودہ ڈیٹا میں معمولی تبدیلی کر کے اسے بڑھانے کی تکنیک (مثلاً تصاویر کو گھمانا)۔
*   **Data Drift (ڈیٹا کا بہاؤ):** جب وقت کے ساتھ ان پٹ ڈیٹا کی شماریاتی خصوصیات بدل جائیں، جس سے ماڈل کی کارکردگی متاثر ہو۔
*   **Data Leakage (ڈیٹا کا رساؤ):** جب ٹریننگ ڈیٹا سے باہر کی معلومات ماڈل بنانے میں استعمال ہو جائیں، جس سے نتائج حقیقت سے زیادہ اچھے لگنے لگیں۔
*   **Data Poisoning (ڈیٹا کا زہر):** ایک حملہ جہاں ٹریننگ ڈیٹا کو خراب کر دیا جاتا ہے تاکہ ماڈل غلط کام کرے۔
*   **Decision Tree (فیصلے کا درخت):** فیصلوں اور ان کے ممکنہ نتائج کو سمجھنے کے لیے ایک درخت نما ماڈل۔
*   **Decoding Strategy (ڈی کوڈنگ کی حکمت عملی):** اگلے لفظ (token) کے انتخاب کا طریقہ۔
*   **Deep Learning (ڈیپ لرننگ):** مشین لرننگ کا وہ حصہ جو نیورل نیٹ ورکس پر مبنی ہو۔
*   **Deepfakes (ڈیپ فیکس):** مصنوعی میڈیا جس میں کسی شخص کے چہرے یا جسم کو کسی دوسرے سے بدل دیا جاتا ہے۔
*   **Dense Retrieval:** الفاظ کے بجائے ان کے مفہوم (embeddings) کی بنیاد پر معلومات تلاش کرنا۔
*   **Differential Privacy:** کسی ڈیٹا سیٹ سے معلومات شیئر کرنے کا ایسا ریاضیاتی طریقہ جس سے کسی فرد کی انفرادی شناخت ظاہر نہ ہو۔
*   **Diffusion Model:** ایک ایسا ماڈل جو صاف ڈیٹا سے دھندلاہٹ (noise) ختم کرنا سیکھتا ہے، یہ بہترین تصاویر بنانے کے لیے استعمال ہوتا ہے۔
*   **Distillation (کشید کرنا):** ایک بڑے ماڈل کی معلومات کو چھوٹے ماڈل میں منتقل کرنے کا عمل۔
*   **Domain Adaptation:** ایک شعبے میں ٹرین کیے گئے ماڈل کی دوسرے شعبے میں کام کرنے کی صلاحیت۔
*   **Dropout:** تربیت کے دوران کچھ نیورل یونٹس کو عارضی طور پر روکنے کی تکنیک تاکہ ماڈل صرف ٹریننگ ڈیٹا تک محدود نہ رہ جائے۔

## E

*   **Early Stopping:** ٹریننگ کو وقت سے پہلے روکنے کا عمل تاکہ ماڈل بہت زیادہ مخصوص نہ ہو جائے۔
*   **Edge AI (ایج اے آئی):** اے آئی الگورتھمز کو کلاؤڈ کے بجائے براہِ راست ہارڈ ویئر ڈیوائس پر چلانا۔
*   **ELIZA Effect:** انسانوں کا یہ رجحان کہ وہ کمپیوٹر کے برتاؤ کو غیر ارادی طور پر انسانی برتاؤ کے مشابہ سمجھنے لگتے ہیں۔
*   **Embedding (ایمبیڈنگ):** متن یا تصاویر کی عددی (vector) نمائندگی۔ ہم معنی تصورات اس جگہ میں ایک دوسرے کے قریب ہوتے ہیں۔
*   **Embodied AI:** ایسے اے آئی ایجنٹس جو مادی دنیا کے ساتھ تعامل کرتے ہیں (مثلاً روبوٹس)۔
*   **Ensemble Learning:** کسی ایک الگورتھم کے بجائے کئی الگورتھمز کے نتائج کو ملا کر بہتر پیشگوئی حاصل کرنا۔
*   **Entropy (اینٹروپی):** بے ترتیبی یا معلومات کی مقدار کی پیمائش۔
*   **Epoch (ایپوک):** ٹریننگ ڈیٹا کے مکمل سیٹ سے ایک بار گزرنے کا عمل۔
*   **Ethics of AI (اے آئی کی اخلاقیات):** مصنوعی ذہانت کے سسٹمز سے متعلق اخلاقی پہلوؤں کا مطالعہ۔
*   **Evaluation (تجزیہ):** ماڈل کے نتائج کے معیار کو ناپنے کا عمل۔
*   **Explainable AI (وضاحت طلب اے آئی):** ایسا اے آئی جس کے فیصلوں کی وجہ انسان سمجھ سکیں۔

## F

*   **F1 Score:** درستی (precision) اور یاد دہانی (recall) کا ایک اوسط پیمانہ۔
*   **Fairness (انصاف):** کسی بھی فرد یا گروہ کے خلاف تعصب یا امتیازی سلوک کی عدم موجودگی۔
*   **Feature Engineering:** خام ڈیٹا سے اہم معلومات نکالنے کا عمل۔
*   **Feature Store:** ایم ایل اوپس (MLOps) میں ڈیٹا مینیجمنٹ کا مرکزی حصہ۔
*   **Federated Learning:** ڈیٹا کو کسی ایک جگہ جمع کیے بغیر مختلف ڈیوائسز پر ٹریننگ کا عمل۔
*   **Few-Shot Learning:** ماڈل کی چند مثالوں کے ذریعے نیا کام سیکھنے کی صلاحیت۔
*   **Fine-Tuning (فائن ٹیوننگ):** پہلے سے ٹرین کیے گئے ماڈل کو کسی خاص کام کے لیے مزید ٹرین کرنا۔
*   **Foundation Model (بنیادی ماڈل):** ایک ایسا بڑا ماڈل جسے وسیع ڈیٹا پر ٹرین کیا گیا ہو اور اسے مختلف کاموں کے لیے ڈھالا جا سکے۔
*   **Function Calling:** ایل ایل ایم کی وہ صلاحیت جس کے تحت وہ کوڈ کے کسی مخصوص فنکشن کو چلا سکے۔

## G

*   **GAN (Generative Adversarial Network):** دو نیورل نیٹ ورکس کا ایک ایسا فریم ورک جو ایک دوسرے کے مقابلے میں کام کرتے ہیں۔
*   **Generalization (عمومیت):** ماڈل کی نئے اور ان دیکھے ڈیٹا پر صحیح کام کرنے کی صلاحیت۔
*   **Generative AI (جنریٹیو اے آئی):** ایسا اے آئی جو متن، تصاویر یا دیگر مواد تیار کر سکے۔
*   **Gradient Descent:** ایک ریاضیاتی طریقہ جس کے ذریعے ماڈل کے نقص (loss) کو کم سے کم کیا جاتا ہے۔
*   **Gradient Explosion (گریڈیئنٹ کا دھماکہ):** ٹریننگ کے دوران نیورل نیٹ ورک کی تبدیلیوں کا بہت بڑا ہو جانا جس سے سسٹم غیر مستحکم ہو جائے۔
*   **Gradient Vanishing (گریڈیئنٹ کا غائب ہونا):** ٹریننگ کے دوران تبدیلیوں کا اتنا کم ہو جانا کہ ماڈل مزید سیکھ نہ سکے۔
*   **Graph Neural Network (GNN):** جڑے ہوئے ڈیٹا (graphics) پر کام کرنے والے نیورل نیٹ ورکس۔
*   **Ground Truth:** وہ معلومات جو حقیقت میں درست ثابت ہو چکی ہوں اور جنہیں معیار کے طور پر استعمال کیا جائے۔
*   **Grounding (بنیاد فراہم کرنا):** ماڈل کے نتائج کو حقیقی دنیا کے حقائق سے جوڑنا تاکہ وہ غلط بیانی (hallucination) نہ کرے۔

## H

*   **Hallucination (غلط بیانی):** جب اے آئی پورے اعتماد کے ساتھ غلط یا بے معنی معلومات فراہم کرے۔
*   **Heuristic (ہیروسٹک):** کسی مسئلے کو تیزی سے حل کرنے کی تکنیک جہاں روایتی طریقے سست ہوں۔
*   **Hidden Layer (خفیہ تہہ):** ان پٹ اور آؤٹ پٹ کے درمیان موجود نیورونز کی تہیں جہاں اصل حساب کتاب ہوتا ہے۔
*   **Human-in-the-Loop (HITL):** ایک ایسا ڈیزائن جہاں کسی بھی بڑے عمل سے پہلے انسانی منظوری لازمی ہو۔
*   **Hyperparameter:** وہ سیٹنگز جو ٹریننگ کے عمل کو کنٹرول کرتی ہیں (مثلاً سیکھنے کی رفتار)۔

## I

*   **ImageNet:** تصاویر کا ایک بہت بڑا ڈیٹابیس جو اشیاء کو پہچاننے کی تحقیق کے لیے استعمال ہوتا ہے۔
*   **Imitation Learning:** مثالوں اور نمونوں کے ذریعے سیکھنا۔
*   **In-Context Learning:** ایل ایل ایم کی وہ صلاحیت جہاں وہ پرامپٹ کے اندر دی گئی معلومات سے فوراً سیکھ لے۔
*   **Inference (انفرینس):** ٹرین کیے گئے ماڈل کو نئے ڈیٹا پر استعمال کر کے نتائج حاصل کرنا۔
*   **Information Retrieval (معلومات کی بازیابی):** ڈیٹا کے بڑے ذخیرے سے صحیح معلومات تلاش کرنا۔
*   **InstructGPT:** انسانی ہدایات پر بہتر عمل کرنے والا جی پی ٹی کا ایک ورژن۔
*   **Instruction Tuning:** ماڈل کو سوال اور جواب کی شکل میں ٹرین کرنے کا عمل۔
*   **Interpretable AI:** ایسے سسٹمز جہاں صارف فیصلے کی وجہ جان سکے۔

## J

*   **Jailbreak (جیل بریک):** ایسا پرامپٹ جو اے آئی کے حفاظتی فلٹرز کو نظر انداز کرنے کے لیے بنایا گیا ہو۔
*   **Joint Probability:** دو واقعات کے ایک ساتھ ہونے کا احتمال (probability)۔
*   **JSON Mode:** ایل ایل ایم کا وہ موڈ جو اسے تمام جوابات ایک خاص فارمیٹ (JSON) میں دینے پر مجبور کرے۔

## K

*   **K-Means Clustering:** ڈیٹا کو مختلف گروہوں (clusters) میں تقسیم کرنے کا ایک طریقہ۔
*   **K-Nearest Neighbors (KNN):** ڈیٹا کی درجہ بندی کا ایک سادہ طریقہ۔
*   **Knowledge Graph (نالج گراف):** معلومات کو نوڈس (Node) اور تعلقات کی شکل میں منظم کرنا۔

## L

*   **Labeling (لیبلنگ):** خام ڈیٹا کی شناخت کرنا اور اس میں معنی خیز لیبلز شامل کرنا۔
*   **LangChain:** لسانی ماڈلز (LLMs) پر مبنی ایپلیکیشنز بنانے کا ایک فریم ورک۔
*   **Large Language Model (LLM):** ایک ایسا ماڈل جو انسانی زبان کو سمجھنے اور تیار کرنے کی صلاحیت رکھتا ہو۔
*   **Latent Space:** ڈیٹا کی ایک مختصر اور جامع نمائندگی۔
*   **Learning Rate (سیکھنے کی رفتار):** ایک پیمانہ جو یہ طے کرتا ہے کہ ماڈل اپنے وزن (weights) میں کتنی تیزی سے تبدیلی لائے۔
*   **Long Short-Term Memory (LSTM):** نیورل نیٹ ورک کا ایک خاص ڈیزائن جو طویل عرصے تک معلومات یاد رکھ سکتا ہے۔
*   **Loss Function:** ایک ریاضیاتی فارمولا جو یہ بتاتا ہے کہ ماڈل کی پیشگوئی اصل جواب سے کتنی دور ہے۔

## M

*   **Machine Learning (مشین لرننگ):** کمپیوٹر کے ایسے الگورتھمز کا مطالعہ جو تجربے کے ساتھ خود بخود بہتر ہوتے ہیں۔
*   **Machine Unlearning:** ٹرین کیے گئے ماڈل سے مخصوص ڈیٹا کے اثرات کو ختم کرنے کا عمل۔
*   **MLOps:** مشین لرننگ ماڈلز کو پروفیشنل طریقے سے چلانے اور ان کی دیکھ بھال کے اصول۔
*   **Model Card (ماڈل کارڈ):** ایک دستاویز جو ماڈل کی صلاحیتوں اور حدود کو بیان کرتی ہے۔
*   **Model Collapse (ماڈل کا زوال):** جب ماڈلز مصنوعی ڈیٹا پر ہی ٹرین ہوتے رہیں اور ان کی کارکردگی بگڑ جائے۔
*   **Monte Carlo Tree Search (MCTS):** فیصلوں کے عمل میں بہترین راستہ تلاش کرنے کا ایک طریقہ۔
*   **Mixture of Experts (MoE):** ایک ایسا ڈیزائن جہاں کئی چھوٹے ماڈلز مل کر ایک بڑا ماڈل بناتے ہیں (جیسے GPT-4)۔
*   **Multi-Agent System (MAS):** ایسا سسٹم جہاں کئی ذہین ایجنٹس آپس میں مل کر کام کریں۔
*   **Multi-Modal:** وہ ماڈلز جو بیک وقت متن، تصاویر اور آواز کو سمجھ سکیں۔

## N

*   **Natural Language Processing (NLP):** کمپیوٹر اور انسانی زبان کے درمیان تعامل کا مطالعہ۔
*   **Natural Language Understanding (NLU):** مشینوں کی انسانی زبان کو سمجھنے کی صلاحیت۔
*   **Neuro-symbolic AI:** نیورل نیٹ ورکس کو منطقی قوانین کے ساتھ ملا کر استعمال کرنا۔
*   **Normalization (نارملائزیشن):** ڈیٹا کو ایک معیاری پیمانے پر لانا۔
*   **Nucleus Sampling (Top-p):** الفاظ کے انتخاب کی ایک حکمت عملی جو صرف اہم الفاظ پر توجہ دیتی ہے۔

## O

*   **Object Detection:** تصویر یا ویڈیو میں اشیاء کی موجودگی اور مقام کا پتہ لگانا۔
*   **One-Shot Learning:** صرف ایک مثال سے سیکھنے کی صلاحیت۔
*   **Online Learning:** ایسا سسٹم جو مسلسل آنے والے ڈیٹا سے ساتھ ساتھ سیکھتا رہے۔
*   **OpenAI Gym:** ری انفورسمنٹ لرننگ کے الگورتھمز کو جانچنے کا ایک ٹول۔
*   **Out-of-Distribution (OOD):** ایسا ڈیٹا جو ٹریننگ ڈیٹا سے بالکل مختلف ہو۔
*   **Overfitting:** جب ماڈل ٹریننگ ڈیٹا کو اتنا زیادہ یاد کر لے کہ وہ نئے ڈیٹا پر صحیح کام نہ کر سکے۔

## P

*   **Parameter (پیرامیٹر):** ماڈل کے اندر موجود وہ متغیرات (variables) جن کی قیمت ٹریننگ کے دوران طے ہوتی ہے۔
*   **Parameter Efficient Fine-Tuning (PEFT):** تمام پیرامیٹرز کے بجائے صرف چند کو تبدیل کر کے ماڈل کو بہتر بنانے کی تکنیک (مثلاً LoRA)۔
*   **Perplexity (پرپلیکسٹی):** اس بات کا پیمانہ کہ ایک ماڈل کتنی اچھی پیشگوئی کر رہا ہے۔ یہ جتنا کم ہو اتنا بہتر ہے۔
*   **Policy (RL):** ایک ایسی حکمت عملی جو ایجنٹ کو اگلے قدم کا فیصلہ کرنے میں مدد دیتی ہے۔
*   **Precision (درستی):** فراہم کیے گئے نتائج میں سے صحیح نتائج کا تناسب۔
*   **Pre-training:** کسی خاص کام سے پہلے ماڈل کو بڑے ڈیٹا پر عام تربیت دینا۔
*   **Prompt Engineering:** ماڈل سے بہتر نتائج حاصل کرنے کے لیے سوال یا ہدایات کو بہترین طریقے سے لکھنا۔
*   **Prompt Injection:** ایک حملہ جہاں صارف سسٹم کی ہدایات کو بدلنے کی کوشش کرتا ہے۔
*   **Pruning (چھانٹی):** نیورل نیٹ ورک سے غیر ضروری پیرامیٹرز کو ہٹانا۔

## Q

*   **Q-Learning:** ری انفورسمنٹ لرننگ کا ایک ماڈل فری الگورتھم۔
*   **Quantization (کوانٹائزیشن):** ماڈل کے پیرامیٹرز کی عددی درستی کو کم کرنا تاکہ وہ کم جگہ گھیرے اور تیز چل سکے۔
*   **Query Expansion:** صارف کے سوال کو بہتر بنانے کے لیے اس میں مزید الفاظ شامل کرنا۔

## R

*   **RAG (Retrieval-Augmented Generation):** ایل ایل ایم کو بیرونی ڈیٹا فراہم کر کے سوالات کے جوابات حاصل کرنے کی تکنیک۔
*   **ReAct (Reason + Act):** ایک ایسا طریقہ جہاں ایجنٹ سوچنے اور عمل کرنے کو ساتھ ساتھ چلاتا ہے۔
*   **Recall:** تمام درست نتائج میں سے ان نتائج کی شرح جو سسٹم نے تلاش کیے۔
*   **Recommendation System (سفارشی نظام):** ایسا سسٹم جو صارف کی پسند کے مطابق اشیاء کی تجویز دے۔
*   **Recurrent Neural Network (RNN):** نیورل نیٹ ورکس کی وہ قسم جو کسی سلسلے (sequence) والے ڈیٹا کے لیے استعمال ہوتی ہے۔
*   **Red Teaming (ریڈ ٹیمنگ):** سسٹم کی خامیوں کو ڈھونڈنے کے لیے اس پر حملہ آور کے طور پر کام کرنا۔
*   **Reinforcement Learning (RL):** سیکھنے کا وہ عمل جہاں ایجنٹ اپنے ماحول میں کام کر کے انعامات (rewards) کے ذریعے بہتر ہوتا ہے۔
*   **Reinforcement Learning from Human Feedback (RLHF):** انسانی رائے کے ذریعے ماڈل کو ٹرین کرنا۔
*   **Reward Function:** وہ فارمولا جو یہ طے کرتا ہے کہ ایجنٹ کو کسی کام پر کتنے پوائنٹس ملیں گے۔
*   **Reward Hacking:** ایجنٹ کا وہ عمل جہاں وہ اصل ہدف کے بجائے صرف زیادہ پوائنٹس حاصل کرنے کا کوئی راستہ نکال لے۔
*   **Robustness (پائیداری):** سسٹم کی اپنی غلطیوں کو سنبھالنے اور مشکل حالات میں کام کرنے کی صلاحیت۔

## S

*   **Scaling Laws:** ماڈل کی کارکردگی، ڈیٹا کی مقدار اور کمپیوٹنگ پاور کے درمیان تعلق کے اصول۔
*   **Self-Attention:** ایک ایسی تکنیک جہاں ماڈل جملے کے مختلف حصوں کے درمیان تعلق کو سمجھتا ہے۔
*   **Self-Supervised Learning:** ایسا طریقہ جہاں ڈیٹا خود ہی اپنی نگرانی کرتا ہے (جیسے چھپے ہوئے الفاظ کا اندازہ لگانا)۔
*   **Semantic Search:** الفاظ کے بجائے ان کے مفہوم کی بنیاد پر تلاش کرنا۔
*   **Sentiment Analysis:** متن سے مثبت یا منفی جذبات کا پتہ لگانا۔
*   **Sigmoid Function:** ایک ریاضیاتی فنکشن جس کی گراف شکل "S" جیسی ہوتی ہے۔
*   **Sim2Real:** سمولیشن (نقل) میں سیکھی گئی چیزوں کو حقیقی دنیا میں لاگو کرنا۔
*   **Singularity (سنگولیریٹی):** وہ مفروضی وقت جب ٹیکنالوجی کی ترقی انسانی قابو سے باہر ہو جائے۔
*   **Synthetic Data:** مصنوعی طور پر تیار کردہ ڈیٹا جو حقیقی واقعات سے نہ لیا گیا ہو۔
*   **System Prompt:** وہ بنیادی ہدایات جو اے آئی کی شخصیت اور حدود کا تعین کرتی ہیں۔

## T

*   **Temperature (ٹمپریچر):** اے آئی کے جوابات میں غیر متوقع پن (randomness) کو کنٹرول کرنے والی سیٹنگ۔
*   **Tensor (ٹینسر):** اعداد کا ایک کثیر الجہتی مجموعہ یا میٹرکس۔
*   **Token (ٹوکن):** متن کا ایک چھوٹا حصہ (لفظ یا لفظ کا حصہ) جو اے آئی پراسیس کرتی ہے۔
*   **Tool Use:** ایجنٹ کی بیرونی سافٹ ویئرز (کیلکولیٹر، سرچ وغیرہ) استعمال کرنے کی صلاحیت۔
*   **Training Data (ٹریننگ ڈیٹا):** وہ ڈیٹا جو ماڈل کو سکھانے کے لیے استعمال ہوتا ہے۔
*   **Transfer Learning:** ایک مسئلے کو حل کرتے وقت حاصل کی گئی معلومات کو دوسرے مسئلے میں استعمال کرنا۔
*   **Transformer (ٹرانسفارمر):** جدید اے آئی کا وہ ڈیزائن جو بیک وقت پورے ڈیٹا کو دیکھ سکتا ہے۔
*   **Turing Test:** اس بات کی جانچ کہ کیا کوئی مشین انسان جیسی ذہانت کا مظاہرہ کر سکتی ہے۔

## U

*   **Underfitting:** جب ماڈل اتنا سادہ ہو کہ وہ ڈیٹا کے بنیادی رجحانات کو بھی نہ سمجھ سکے۔
*   **Unsupervised Learning:** بغیر کسی رہنمائی یا لیبلز کے ڈیٹا سے خود بخود سیکھنا۔
*   **Utility Function:** ایک فنکشن جو مختلف اقدامات کو ان کے فائدے کے لحاظ سے درجہ بندی کرتا ہے۔

## V

*   **Validation Set:** ٹریننگ کے دوران ماڈل کی کارکردگی چیک کرنے کے لیے استعمال ہونے والا ڈیٹا۔
*   **Vector Database (ویکٹر ڈیٹا بیس):** پیچیدہ ڈیٹا (جیسے مفہوم) کو ذخیرہ کرنے اور تلاش کرنے کے لیے مخصوص ڈیٹا بیس۔
*   **Vision Transformer (ViT):** تصاویر کی درجہ بندی کے لیے ٹرانسفارمر فارمیٹ کا استعمال۔

## W

*   **Weights (وزن):** نیورل نیٹ ورک کے پیرامیٹرز جنہیں سیکھنے کے دوران بدلا جا سکتا ہے۔
*   **Word Embedding:** الفاظ کو نمبروں کی شکل میں بدلنا تاکہ ان کے معنی محفوظ رہیں۔
*   **World Model:** ماحول کی ایک اندرونی تصویر جو ایجنٹ کو اپنے مستقبل کے اقدامات کے نتائج سوچنے میں مدد دیتی ہے۔

## X

*   **X-Risk (خطرہِ مٹاؤ):** وہ خطرہ کہ اے آئی انسانی تہذیب کی تباہی کا باعث بن سکتی ہے۔

## Z

*   **Zero-Shot Learning:** بغیر کسی پیشگی تربیت یا مثال کے نیا کام کرنے کی صلاحیت۔
*   **Zero Trust (زیرو ٹرسٹ):** ایک حفاظتی ڈھانچہ جہاں کسی بھی صارف یا سسٹم پر اعتبار نہیں کیا جاتا جب تک وہ ثابت نہ ہو۔
